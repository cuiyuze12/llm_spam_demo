from langchain_aws import ChatBedrock
from langchain_aws.retrievers import AmazonKnowledgeBasesRetriever
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
import boto3


session = boto3.Session()
kb_client = session.client("bedrock-runtime", region_name="us-east-1")

# åˆæœŸåŒ–ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«ä¸€åº¦ã ã‘è¡Œã†ï¼ˆFastAPIã®èµ·å‹•æ™‚ï¼‰
retriever = AmazonKnowledgeBasesRetriever(
    knowledge_base_id="PFGPGVDWRJ",
    retrieval_config={"vectorSearchConfiguration": {"numberOfResults": 10}},
    region_name="us-east-1"  # æ˜¾å¼æŒ‡å®šåŒºåŸŸ
)

prompt = ChatPromptTemplate.from_template(
    "ä»¥ä¸‹ã®contextã«åŸºã¥ã„ã¦ã€ã§ãã‚‹ã ã‘ä¸å¯§ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\nContext:\n{context}\n\nè³ªå•:\n{question}"
)


model = ChatBedrock(
    client=kb_client,
    model_id="anthropic.claude-3-sonnet-20240229-v1:0",
    model_kwargs={"max_tokens": 1000},
)

# ãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹æˆ
rag_chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | model
        | StrOutputParser()
)

# FastAPIã‹ã‚‰å‘¼ã³å‡ºã›ã‚‹é–¢æ•°
def real_rag_answer(question: str) -> str:
    try:
        # Step 1: å…ˆç‹¬ç«‹è°ƒç”¨æ£€ç´¢
        docs = retriever.get_relevant_documents(question)

        if not docs:  # æ£€ç´¢ç»“æœä¸ºç©º
            return "ğŸ” ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«è©²å½“æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

        # Step 2: è‹¥å‘½ä¸­ï¼Œç»§ç»­æ‰§è¡Œ RAG Chain
        return rag_chain.invoke(question)
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
