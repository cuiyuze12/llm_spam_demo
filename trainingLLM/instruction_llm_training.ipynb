{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##0.概要\n",
        "本ノートブックでは、GPT-2 をベースとした軽量LLMを PyTorch でファインチューニングし、ユーザーからの自由な指示（prompt）に応じて応答を生成する小型モデルを構築・学習・推論します。  \n",
        "学習済みモデルは `.pth` ファイルとして保存され、さらに EC2 上の FastAPI を通じて API 化されており、Web 画面から自由にアクセスすることができます。"
      ],
      "metadata": {
        "id": "gg3a71gPIx1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.環境の準備\n",
        "必要なパッケージとライブラリのインポート\n"
      ],
      "metadata": {
        "id": "97ftYi-hMtOh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaEHOZFEJqDH",
        "outputId": "9b4418ee-dfec-4548-d600-b6dcd703fd49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy version: 2.0.2\n",
            "matplotlib version: 3.10.0\n",
            "tiktoken version: 0.9.0\n",
            "torch version: 2.6.0+cu124\n",
            "tqdm version: 4.67.1\n",
            "tensorflow version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\n",
        "    \"numpy\",       # PyTorch & TensorFlow dependency\n",
        "    \"matplotlib\",  # Plotting library\n",
        "    \"tiktoken\",    # Tokenizer\n",
        "    \"torch\",       # Deep learning library\n",
        "    \"tqdm\",        # Progress bar\n",
        "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
        "]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.データセットの準備"
      ],
      "metadata": {
        "id": "BRqR_BxWNBpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "\n",
        "    # The book originally contained this unnecessary \"else\" clause:\n",
        "    #else:\n",
        "    #    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    #        text_data = file.read()\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKimwfn9KFSS",
        "outputId": "d7fad7f0-4884-435d-848e-6dd99ef2c29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lloM_l_bKNww",
        "outputId": "0571e6ef-ee0b-462f-90b9-7ce043a4de6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Another example entry:\\n\", data[999])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slwR7dtXKk5e",
        "outputId": "a012c0f8-1a96-4076-9ddf-a3492d8ff304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Another example entry:\n",
            " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ],
      "metadata": {
        "id": "Qv32nP8xLJS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r23D_IKQLaY1",
        "outputId": "fbac7060-aa0a-424d-a529-867c1207ace7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(data[999])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2vfC-ZbLkhm",
        "outputId": "e7958957-c86d-4d9c-971c-1cc601b5889e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            "### Response:\n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ],
      "metadata": {
        "id": "VWLP0VuOLnxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6xoWBSNLqqq",
        "outputId": "c570c091-3664-4ed9-f398-867694d5b1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "uz1jAC_BLtsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHP4oHXpMKqF",
        "outputId": "efb81afa-ecc0-41e3-be33-0c9e5f133689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    # and increase the max length by +1, which will add one extra\n",
        "    # padding token below\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to batch_max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        # Via padded[:-1], we remove the extra padded token\n",
        "        # that has been added via the +1 setting in batch_max_length\n",
        "        # (the extra padding token will be relevant in later codes)\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ],
      "metadata": {
        "id": "1p4hVk49NnZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_draft_1(batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt2S7Ij2NvST",
        "outputId": "0a1daa5f-a4c1-40d0-8ac9-6efd5c90c3c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_2(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "T_kwZkKkN_8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY_kKBmnOctO",
        "outputId": "f098df9c-a5a5-404e-a6a1-13f2d80472b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "NAUtM6ztOgY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YdDhlyaO1lm",
        "outputId": "86d421df-b763-4a86-b86d-c51f0345694d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_1 = torch.tensor(\n",
        "    [[-1.0, 1.0],  # 1st training example\n",
        "     [-0.5, 1.5]]  # 2nd training example\n",
        ")\n",
        "targets_1 = torch.tensor([0, 1])\n",
        "\n",
        "\n",
        "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
        "print(loss_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqGp8X9sO7an",
        "outputId": "bf694c8e-6c13-47ee-8d36-d9cd64aee8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1269)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_2 = torch.tensor(\n",
        "    [[-1.0, 1.0],\n",
        "     [-0.5, 1.5],\n",
        "     [-0.5, 1.5]]  # New 3rd training example\n",
        ")\n",
        "targets_2 = torch.tensor([0, 1, 1])\n",
        "\n",
        "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
        "print(loss_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTnINt4bO_QQ",
        "outputId": "0d326ef9-7f51-441a-e8f6-c3b1c3398214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7936)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets_3 = torch.tensor([0, 1, -100])\n",
        "\n",
        "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
        "print(loss_3)\n",
        "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x-caP7HPIF6",
        "outputId": "2a32b068-73ee-45de-e1f5-42cec2cf906e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1269)\n",
            "loss_1 == loss_3: tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# However, the resulting loss values may be slightly different.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua1HLFAkPSOW",
        "outputId": "64dac70d-f94a-4cab-91fd-a49f82675898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    allowed_max_length=1024\n",
        ")"
      ],
      "metadata": {
        "id": "N6Lq-iY4PVVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "id": "JQjKQBhAPacx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "id": "awQ4VeE9Pg3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS5fiuDMPpk_",
        "outputId": "5d20ced7-8f43-46a8-e038-206d38c5cf05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PoagsPwPuPI",
        "outputId": "b5884bda-d220-4cef-c8d8-8f9e55b11f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
            "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
            "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
            "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
            "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
            "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(targets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Siwzct7dQmsk",
        "outputId": "df760965-9f4c-4224-fabf-c2f708231fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
            "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
            "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
            "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
            "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
            "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.モデルの構築"
      ],
      "metadata": {
        "id": "ss3EPxuvP7_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2).contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "        return context_vec\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_shortcut(self.att(self.norm1(x)))\n",
        "        x = x + self.drop_shortcut(self.ff(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "        )\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest logits value\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n"
      ],
      "metadata": {
        "id": "xAwd5a6LVXG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# import requests\n",
        "import tensorflow as tf\n",
        "import tiktoken\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text)\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path)\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "def download_file(url, destination):\n",
        "    # Send a GET request to download the file\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        # Get the total file size from headers, defaulting to 0 if not present\n",
        "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
        "\n",
        "        # Check if file exists and has the same size\n",
        "        if os.path.exists(destination):\n",
        "            file_size_local = os.path.getsize(destination)\n",
        "            if file_size == file_size_local:\n",
        "                print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                return\n",
        "\n",
        "        # Define the block size for reading the file\n",
        "        block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "        # Initialize the progress bar with total file size\n",
        "        progress_bar_description = os.path.basename(url)  # Extract filename from URL\n",
        "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
        "            # Open the destination file in binary write mode\n",
        "            with open(destination, \"wb\") as file:\n",
        "                # Read the file in chunks and write to destination\n",
        "                while True:\n",
        "                    chunk = response.read(block_size)\n",
        "                    if not chunk:\n",
        "                        break\n",
        "                    file.write(chunk)\n",
        "                    progress_bar.update(len(chunk))  # Update progress bar\n",
        "\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params\n",
        "\n",
        "\n",
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))\n",
        "\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n",
        "\n",
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "jL3cLhrEQ0Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.モデルの学習\n"
      ],
      "metadata": {
        "id": "TOi8ErbNQfK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Dt4hPmSQ4Cm",
        "outputId": "e65f64ff-d95e-4a8b-c62c-964724c7e0e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6L1L4_uShnt",
        "outputId": "fadde123-f80b-4f33-d629-1ce750b7058b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ],
      "metadata": {
        "id": "Cocch2-ZSlJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_text = (\n",
        "    generated_text[len(input_text):]\n",
        "    .replace(\"### Response:\", \"\")\n",
        "    .strip()\n",
        ")\n",
        "print(response_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V03jt0CDTqtO",
        "outputId": "127a67c0-90e4-4342-87cc-40630372bc77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()\n",
        "\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen = 0\n",
        "    global_step = -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()  # Calculate loss gradients\n",
        "            optimizer.step()  # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ],
      "metadata": {
        "id": "U0Ef-rFmT2DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwg19WwVT8LY",
        "outputId": "eeb09fb6-6fd7-484e-b817-2f63d1e35f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 3.825909471511841\n",
            "Validation loss: 3.761934232711792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3RM_pkeUFMK",
        "outputId": "5eb973cd-901d-4efc-fe9f-713930e2fd10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
            "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
            "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
            "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
            "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
            "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
            "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
            "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
            "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
            "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
            "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
            "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
            "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
            "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
            "Ep 1 (Step 000070): Train loss 0.533, Val loss 0.729\n",
            "Ep 1 (Step 000075): Train loss 0.568, Val loss 0.729\n",
            "Ep 1 (Step 000080): Train loss 0.604, Val loss 0.725\n",
            "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.710\n",
            "Ep 1 (Step 000090): Train loss 0.563, Val loss 0.691\n",
            "Ep 1 (Step 000095): Train loss 0.502, Val loss 0.681\n",
            "Ep 1 (Step 000100): Train loss 0.504, Val loss 0.677\n",
            "Ep 1 (Step 000105): Train loss 0.565, Val loss 0.670\n",
            "Ep 1 (Step 000110): Train loss 0.554, Val loss 0.666\n",
            "Ep 1 (Step 000115): Train loss 0.509, Val loss 0.663\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
            "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.671\n",
            "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.686\n",
            "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
            "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.681\n",
            "Ep 2 (Step 000140): Train loss 0.410, Val loss 0.681\n",
            "Ep 2 (Step 000145): Train loss 0.369, Val loss 0.681\n",
            "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
            "Ep 2 (Step 000155): Train loss 0.414, Val loss 0.675\n",
            "Ep 2 (Step 000160): Train loss 0.412, Val loss 0.684\n",
            "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
            "Ep 2 (Step 000170): Train loss 0.322, Val loss 0.680\n",
            "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.668\n",
            "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
            "Ep 2 (Step 000185): Train loss 0.414, Val loss 0.657\n",
            "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
            "Ep 2 (Step 000195): Train loss 0.328, Val loss 0.634\n",
            "Ep 2 (Step 000200): Train loss 0.309, Val loss 0.634\n",
            "Ep 2 (Step 000205): Train loss 0.353, Val loss 0.631\n",
            "Ep 2 (Step 000210): Train loss 0.362, Val loss 0.631\n",
            "Ep 2 (Step 000215): Train loss 0.393, Val loss 0.634\n",
            "Ep 2 (Step 000220): Train loss 0.297, Val loss 0.644\n",
            "Ep 2 (Step 000225): Train loss 0.341, Val loss 0.658\n",
            "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.656\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
            "Training completed in 3.06 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "MgVsK2WBVcvC",
        "outputId": "a0b283fe-80a4-43c8-f1cb-c702238d7831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.モデルの推論テスト"
      ],
      "metadata": {
        "id": "TERHG4KTLmO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        ")\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2VMQwRYVxpk",
        "outputId": "17f5415e-6f4b-42bf-b431-839697fc939b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7COAeAg1V6y8",
        "outputId": "c9ce7c24-f21e-4e9a-c6d5-0a7d421c8e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [01:17<00:00,  1.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfXzqA_WWW8a",
        "outputId": "571fad82-0db6-4d8e-bbf2-e2d82890b4fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.モデルの保存"
      ],
      "metadata": {
        "id": "YQBz91OCQvh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCsld49xWkJt",
        "outputId": "e408d701-81c1-4c7a-c2b0-8bba4ed26ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習済みモデルの保存ファイルを復元し、動作確認としてテストデータで推論を実行"
      ],
      "metadata": {
        "id": "OuU9zFoGL0KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = torch.load(\"gpt2-medium355M-sft.pth\", map_location=device, weights_only=True)\n",
        "model.load_state_dict(model_state_dict)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPvDqmZbaIJL",
        "outputId": "9b243d68-f40d-4a1a-ea14-044b6d2a091e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 1024)\n",
              "  (pos_emb): Embedding(1024, 1024)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (12): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (13): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (14): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (15): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (16): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (17): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (18): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (19): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (20): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (21): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (22): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (23): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Below is an instruction that describes a task. Write a response\n",
        "that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
        "\"\"\"\n",
        "\n",
        "def extract_response(response_text, input_text):\n",
        "    return response_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "idx = text_to_token_ids(prompt, tokenizer).to(device)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=idx,\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256\n",
        ")\n",
        "\n",
        "\n",
        "response = token_ids_to_text(token_ids, tokenizer)\n",
        "response = extract_response(response, prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HW7o6wLbubb",
        "outputId": "c0e0b6a1-684d-47cd-cb1a-094b61016601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The meal is cooked every day by the chef.\n"
          ]
        }
      ]
    }
  ]
}